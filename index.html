<!DOCTYPE html>
<html lang='en'>

<head>
    <base href=".">
    <link rel="shortcut icon" type="image/png" href="assets/favicon.png"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <meta name="description" content="Conference Template">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference">
    <title>Triangle Area Privacy and Security Day</title>
</head>

<body>

    <div class="banner">
        <img src="assets/James-B-Hunt-Jr-Library.jpg" width="1200" 
     height="500" alt="Conference Template Banner">
        <div class="top-left">
            <span class="title1">TAPS </span> <span class="year">2022</span>
        </div>
        <div class="bottom-right">
            Nov 04 <br> North Carolina State University, Raleigh
        </div>
    </div>

<!--     <table class="navigation">
        <tr>
            <td class="navigation">
                <a class="current" title="Conference Home Page" href=".">Home</a>
            </td>
            <td class="navigation">
                <a title="Register for the Conference" href="registration">Registration</a>
            </td>
            <td class="navigation">
                <a title="Conference Program" href="program">Program</a> 
            </td>
            <td class="navigation">
                <a title="Directions to the Conference" href="directions">Directions</a>
            </td>
            <td class="navigation">
                <a title="Conference Flyer" href="flyer">Flyer</a>
            </td>
        </tr>
    </table> -->
    <p>
        The Triangle Area Privacy and Security (TAPS) Day  is a meeting reuniting academics from the Triangle Research Area in North Carolina,  to discuss topics in the area of Security, Privacy and Cryptography.

TAPS 2022 will be hosted on November 4th, 2020 at  NCSU. The even takes place in the Duke Energy Hall in the beautiful Hunt Library.

    </p>
    
     <h2>Venue Information and Parking</h2>
    <p>
       The event will be held at <a href='https://www.csc.ncsu.edu'>North Carolina State University (NCSU) </a>, at the Centennial Campus. Specifically in the <a href='https://www.lib.ncsu.edu/spaces/duke-energy-hall'>IEI Duke Energy Hall CD</a> located in the <a href='https://www.lib.ncsu.edu/hunt-library'>Hunt Library</a>  
        
    </p>


 
        <p>Paid visitor parking is available near Hunt Library at <a href = "https://www.lib.ncsu.edu/hunt-library/parking">Partner's Way Deck or Poulton Pay Lot</a>. The Poulton Pay Lot is directly opposite Hunt Library. To get to Hunt Library from Partners Way Deck, walk down Partners Way (the engineering buildings should be to your left) until you see Hunt Library</p>
        
    <p>If you want to take a break, go checkout the lake at <a href="https://centennial.ncsu.edu/thrive/lake-raleigh">Lake Raleigh</a> </p>
       
    <h2>Program</h2>
    <div>
        
    <h5> 09:00 - 09:05 Opening Remarks </h5>   
    <h5> 09:10 - 10:00 <a href='https://users.cs.duke.edu/~pardis/'>Pardis Emami-Naeini (Duke University)</a> </h5> 

 
    </div>
    
    
    <div>
    <h5> 10:15 - 11:15 <a href='https://www.cs.unc.edu/~saba/'>Saba Eskadarian (UNC)</a> </h5>

    </div>
    
    
    <div>
    <h5> 11:20 - 11:30 Student Highlights - Sravya Yandamuri </h5>
        
    <h5> 11:30 - 11:45 Student Highlights - Varun Madathil </h5>
        
  
    </div>
    
   <div> <h5>11:45 - 1:00 Lunch Break (lunch provided only if registered)
 </h3></div>
    
    <div>
    <h5>01:00 -  02:00 <a href='https://www.kapravelos.com'> Alex Kapravelos (NCSU)</a> </h5>

    
    
    <div>
    <h5> 2:30 - 3:10 <a href='https://anupamdas.org'>Anupam Das (NCSU)</a> </h5>

   <h4> </h4>
    <p></p> 
    </div>
    
    <div>
       <h5> 3:20  - 3:35 Students Highlights - Kai Yue </h5>
        
       <h5> 3:35 - 3:50 Student Highlights - Adam Humphries <\h5>
    
     </div>
    
   
    <h2>Presentations</h2>
    
    <div>
        <h5>Pardis Emami-Naeini </h5>         <div style="float:right"><img src="assets/DSC-7243.jpg" width="100" 
     height="110"></div> 
        <h4>Human-Centric Security and Privacy for Emerging Digital Technologies</h4>
        <p>People are increasingly interacting with advanced digital technologies, including smart devices. However, they are not adequately informed about these technologies' security and privacy practices. I conduct research at the intersection of security, privacy, and human-computer interaction. My interdisciplinary research aims to empower people to have informed and secure interactions with emerging digital technologies through an in-depth exploration of people's privacy and security attitudes, concerns, and practices. In this talk, I will go over some of my past and ongoing research on human-centric security and privacy. I will especially focus on a series of quantitative and qualitative projects I have conducted to design an informative and usable security and privacy label for smart devices.</p>
    </div>

    <div>
        <h5>Saba Eskadarian </h5> <div style="float:right"> <img src="assets/profile.jpg" width="100" height="110"></div> 
        <h4>Cryptographic Techniques for Private and Accountable Messaging</h4>
        <p> This talk will cover new cryptographic techniques that can enable improvements in both the privacy and accountability of messaging systems. I will first describe Clarion (NDSS'22), a system that uses shuffling techniques from the multiparty computation literature to implement fast anonymous messaging. Next, I will discuss the potential for abuse introduced by strong privacy in messaging applications, and I will present recent work on verifiable abuse reporting in metadata-hiding communication systems.
</p>
    </div>

    <div>
        <h5>Alex Kapravelos</h5>        <div style="float:right"><img src="assets/prof.jpg" width="100" 
     height="110"></div>
        <h4>TBD</h4>
        <p>TBD</p>
    </div>

    <div>
        <h5>Anupam Das</h5>        <div style="float:right"><img src="assets/Anupam_Das.jpg" width="110" 
     height="110"></div> 
        <h4>Security and Privacy Analysis of Emerging Voice Interfaces</h4>
        <p>The use of voice-control technology has become mainstream and is growing worldwide. In the US alone, millions of users own voice assistants. Such high adoption rates indicate that voice interfaces are becoming the default interface to smart environments and home automation. As a result, we are also starting to see third-party applications run on top of voice interfaces, similar to how apps run on mobile devices. However, this presents new security and privacy risks for users. In this talk, I will discuss our recent efforts in analyzing the vetting process of third-party applications on the Amazon Alexa platform and the various flaws we discovered. I will also talk about the availability and effectiveness of existing security and privacy indicators, or a lack thereof, to help users properly comprehend the risk of interacting with voice-based third-party applications. 
</p>
    </div>

 <h2>Student Highlights</h2>
        
<div>
        <h5>Sravya Yandamuri</h5>  
        <h4>Efficient and Adaptively Secure Asynchronous Binary Agreement via Binding Crusader Agreement</h4>
        <p>We present a new abstraction based on crusader agreement called Binding Crusader Agreement (BCA) for solving binary consensus in the asynchronous setting against an adaptive adversary. BCA has the validity, agreement, and termination properties of crusader agreement in addition to a new property called binding. Binding states that before the first non-faulty party terminates, there is a value v in {0,1} such that no non-faulty party can output the value v in any continuation of the execution.

We believe that reasoning about binding explicitly, as a first order goal, greatly helps algorithm design, clarity, and analysis. 

Using our framework, we solve several versions of asynchronous binary agreement against an adaptive adversary in a simple and modular manner that either improves or matches the efficiency of state of the art solutions. We do this via new BCA protocols, given a strong common coin, and via new Graded BCA protocols given an epsilon-good common coin.

For crash failures, we reduce the expected time to terminate and we provide termination bounds that are linear in the goodness of the common coin.

For Byzantine failures, we improve the expected time to terminate in the computational setting with threshold signatures, and match the state of the art in the information theoretic setting,  
both with a strong common coin and with an epsilon-good common coin.</p>
    
    <h5>Varun Madathil</h5>
    <h4>Full Privacy for Account-based Cryptocurrencies</h4>
    <p>The public visibility of cryptocurrency payments makes it imperative that these payments, although visible, must be private. Account-based cryptocurrencies (e.g., Ethereum) are based on updating user balances in a global mutable state and no techniques exist to achieve full privacy. Existing approaches to achieve privacy have fundamental limitations in the anonymity they provide.
All existing designs for adding privacy to account-based cryptocurrencies require augmenting the size of a payment transaction from constant (two accounts per transaction) to linear in the anonymity set desired by the account holder. Concretely, this means that the maximum anonymity that an account holder can achieve is upper-bounded by the maximum number of accounts that can be included in the transaction, which is an extremely small fraction of all the existing accounts in the system. As a result, private cryptocurrencies that follow these approaches provide very weak anonymity guarantees.
In this talk, we provide the first approach that guarantees full privacy in account-based cryptocurrencies using compact transactions. </p>
    
    <h5>Kai Yue</h5>
    <h4>Gradient Obfuscation Gives a False Sense of Security in Federated Learning</h4>
    <p>Federated learning has been proposed as a privacy-preserving
machine learning framework that enables multiple clients to
collaborate without sharing raw data. However, client privacy
protection is not guaranteed by design in this framework.
Prior work has shown that the gradient sharing strategies in
federated learning can be vulnerable to data reconstruction
attacks. In practice, though, clients may not transmit raw gradients
considering the high communication cost or due to
privacy enhancement requirements. Empirical studies have
demonstrated that gradient obfuscation, including intentional
obfuscation via gradient noise injection and unintentional obfuscation
via gradient compression, can provide more privacy
protection against reconstruction attacks. In this work, we
present a new reconstruction attack framework targeting the
image classification task in federated learning. We show how
commonly adopted gradient postprocessing procedures, such
as gradient quantization, gradient sparsification, and gradient
perturbation may give a false sense of security in federated
learning. Contrary to prior studies, we argue that privacy enhancement
should not be treated as a byproduct of gradient
compression. Additionally, we design a new method under
the proposed framework to reconstruct images at the semantic
level. We quantify the semantic privacy leakage and compare
it with conventional image similarity scores. Our comparisons
challenge the image data leakage evaluation schemes in the
literature. The results emphasize the importance of revisiting
and redesigning the privacy protection mechanisms for client
data in existing federated learning algorithms.</p>
    
    <h5>Adam Humphries</h5>
    <h4>TASE: Reducing Latency of Symbolic Execution with Transactional Memory</h4>
    <p>We present the design and implementation of a tool
called TASE that uses transactional memory to reduce the latency
of symbolic-execution applications with small amounts of symbolic state. Execution paths are executed natively while operating
on concrete values, and only when execution encounters symbolic
values (or modeled functions) is native execution suspended and
interpretation begun. Execution then returns to its native mode
when symbolic values are no longer encountered. The key innovations in the design of TASE are a technique for amortizing the cost
of checking whether values are symbolic over few instructions,
and the use of hardware-supported transactional memory (TSX)
to implement native execution that rolls back with no effect
when use of a symbolic value is detected (perhaps belatedly).
We show that TASE has the potential to dramatically improve
some latency-sensitive applications of symbolic execution, such
as methods to verify the behavior of a client in a client-server
application.</p>
    </div>
    


   
        
    <h2>Contact</h2>
    <p>
        <img src="assets/JPG-AS.jpg" width="80" 
     height="110">
       <br> Alessandra Scafuro </br>
    <br>  Assistant Professor, NCSU </br>
   <br>  ascafur@ncsu.edu </br>

    </p>
</body>
</html>

